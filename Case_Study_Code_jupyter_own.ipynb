{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Case_Study_Code_jupyter_own.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t6fIXK3Kg0xb",
        "OTqe8geCke8B",
        "ee0ff6ad",
        "OXavZC-WlC7l"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5c3db8a"
      },
      "source": [
        "**VM: Deep Learning mit Python - Model from scratch**\n",
        "\n",
        "*Group: Leo Giesen, Johannes Kauffmann*\n",
        "\n",
        "Case Study: Create deep learning model to predict Land Use and Land Cover data drom satellite pictures."
      ],
      "id": "c5c3db8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6fIXK3Kg0xb"
      },
      "source": [
        "# Imports and definitions"
      ],
      "id": "t6fIXK3Kg0xb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e03219a",
        "outputId": "f85a6d8c-1ede-4523-e87b-cf6c4f1dcae5"
      },
      "source": [
        "# Import of packages\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import calendar\n",
        "import os\n",
        "from google.colab import drive\n",
        "from packaging import version\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse('2.5.0')"
      ],
      "id": "5e03219a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opEjKvyLk4s2",
        "outputId": "ac50e32f-32c0-4a18-f09c-e27d8f58eedc"
      },
      "source": [
        "# mount Google drive to get the data\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "root_path = 'gdrive/My Drive/Wirtschaftsinformatik/lulc_data'"
      ],
      "id": "opEjKvyLk4s2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90bd882"
      },
      "source": [
        "# Class names\n",
        "\n",
        "class_names = {\n",
        "    0: \"No Data\", \n",
        "    1: \"Cultivated Land\",\n",
        "    2: \"Forest\",\n",
        "    3: \"Grassland\",\n",
        "    4: \"Shrubland\",\n",
        "    5: \"Water\",\n",
        "    6: \"Wetlands\",\n",
        "    7: \"Tundra\",\n",
        "    8: \"Artificial Surface\",\n",
        "    9: \"Bareland\",\n",
        "    10: \"Snow and Ice\"\n",
        "}"
      ],
      "id": "f90bd882",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89bafeee"
      },
      "source": [
        "# Channel names\n",
        "\n",
        "channel_names = {\n",
        "    1: \"Red\",\n",
        "    2: \"Green\",\n",
        "    3: \"Blue\",\n",
        "    4: \"NIR 1\",\n",
        "    5: \"NIR 2\",\n",
        "    6: \"NIR 3\"\n",
        "}"
      ],
      "id": "89bafeee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTqe8geCke8B"
      },
      "source": [
        "# Data loading and exploration"
      ],
      "id": "OTqe8geCke8B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "622facde"
      },
      "source": [
        "**Loading data**"
      ],
      "id": "622facde"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64f8087f",
        "outputId": "9f812a04-0190-44ec-d2b2-19c8708279bb"
      },
      "source": [
        "data = data = np.load(root_path + '/train.npz')\n",
        "bands = data['bands'] # data: 10.000 patches, each for twelve months and with six channels. Resolution: 33x33 pixels\n",
        "lulc = data['lulc'] # labels for central pixel of patches (Land Use and Land Cover)\n",
        "print(bands.shape)\n",
        "print(lulc.shape)"
      ],
      "id": "64f8087f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 12, 33, 33, 6)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqHYEAe2lzUe"
      },
      "source": [
        "**Examine data**"
      ],
      "id": "zqHYEAe2lzUe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98968898"
      },
      "source": [
        "%%script false\n",
        "# show number of instances per class\n",
        "\n",
        "count_classes = []\n",
        "for i in range(11): \n",
        "    val = np.count_nonzero(lulc == i)\n",
        "    print(\"class \"+str(i)+\": \"+str(val))\n",
        "    count_classes.append(val)\n",
        "#print(count_classes)"
      ],
      "id": "98968898",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgla0h2ycN09"
      },
      "source": [
        "%%script false\n",
        "# print bar chart\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "classes = list(class_names.values())\n",
        "ax.bar(classes,count_classes)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "id": "fgla0h2ycN09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3abcb8"
      },
      "source": [
        "--> Realization: Class 2 is over-represented. Classes 6, 7 and 10 are not present in the data set at all."
      ],
      "id": "6e3abcb8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da34908c",
        "scrolled": true
      },
      "source": [
        "%%script false\n",
        "# Show some images\n",
        "\n",
        "patch = 250 # random patch number\n",
        "\n",
        "print(\"Channels from patch no. \" + str(patch))\n",
        "print(\"Central pixel is labeled as \" + class_names[lulc[patch]])\n",
        "\n",
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands[patch, month, :, :, channel]\n",
        "        plt.imshow(image, cmap = plt.cm.binary)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\")"
      ],
      "id": "da34908c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648cCzbdg_bm"
      },
      "source": [
        "# Data Preparation"
      ],
      "id": "648cCzbdg_bm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2819dc3d"
      },
      "source": [
        "**Split data into train, validation and test data**"
      ],
      "id": "2819dc3d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaed0901",
        "outputId": "762a1534-6650-4fc4-c6ef-2480eda7c326"
      },
      "source": [
        "X = bands\n",
        "y = lulc\n",
        "\n",
        "# split into train, test, vaildation sets\n",
        "X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.20)\n",
        "print(X_train.shape)"
      ],
      "id": "aaed0901",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6400, 12, 33, 33, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOFxAzX6oKs"
      },
      "source": [
        "# clear variables to save RAM\n",
        "del data\n",
        "del bands\n",
        "del lulc\n",
        "del X\n",
        "del y"
      ],
      "id": "nmOFxAzX6oKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a914c2c"
      },
      "source": [
        "**Class weights** "
      ],
      "id": "9a914c2c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90976991",
        "outputId": "ac1071cd-0590-4ddf-ab89-304679db9302"
      },
      "source": [
        "# Calculate class weights automatically\n",
        "class_weights_array = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "# Create dictionary for the class weights\n",
        "class_weights_dict = {\n",
        "    0: class_weights_array[0],\n",
        "    1: class_weights_array[1],\n",
        "    2: class_weights_array[2],\n",
        "    3: class_weights_array[3],\n",
        "    4: class_weights_array[4],\n",
        "    5: class_weights_array[5],\n",
        "    6: 0,\n",
        "    7: 0,\n",
        "    8: class_weights_array[6],\n",
        "    9: class_weights_array[7],\n",
        "    10: 0,\n",
        "}\n",
        "\n",
        "print(class_weights_dict)"
      ],
      "id": "90976991",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.9815950920245399, 1: 5.298013245033113, 2: 0.21511158913686476, 3: 1.0914051841746248, 4: 1.6326530612244898, 5: 19.047619047619047, 6: 0, 7: 0, 8: 6.015037593984962, 9: 2.5236593059936907, 10: 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ3_3mFhTWrE"
      },
      "source": [
        "**One-hot encoder**"
      ],
      "id": "WJ3_3mFhTWrE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "endRIo0fTSDj"
      },
      "source": [
        "# one-hot encoder for categorical_crossentropy loss to work in model\n",
        "depth = 11\n",
        "y_train = tf.one_hot(y_train, depth)\n",
        "y_val = tf.one_hot(y_val, depth)\n",
        "y_test = tf.one_hot(y_test, depth)"
      ],
      "id": "endRIo0fTSDj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEOzTGMcgoHq"
      },
      "source": [
        "**Data augmentation**"
      ],
      "id": "NEOzTGMcgoHq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8s2bWDmq2o1",
        "outputId": "e2249088-ccb9-4cec-8d55-4456635884e1"
      },
      "source": [
        "#%%script false\n",
        "# Create Tensorflow Dataset objects\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "print(tf.data.experimental.cardinality(train_ds))\n",
        "print(tf.data.experimental.cardinality(val_ds))\n",
        "print(tf.data.experimental.cardinality(test_ds))"
      ],
      "id": "Y8s2bWDmq2o1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6400, shape=(), dtype=int64)\n",
            "tf.Tensor(1600, shape=(), dtype=int64)\n",
            "tf.Tensor(2000, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaqO68xP7Qpu"
      },
      "source": [
        "# clear variables to have more RAM\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val"
      ],
      "id": "AaqO68xP7Qpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdJpGjDSF6ef"
      },
      "source": [
        "Code from: [Tensorflow - Data augmentation Tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)"
      ],
      "id": "EdJpGjDSF6ef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmZOkQDIYz2S",
        "outputId": "9ced0bb4-7488-495c-a053-a86d087656dd"
      },
      "source": [
        "#%%script false\n",
        "# create data augmentation layer\n",
        "data_augmentation_ver = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('vertical'),\n",
        "    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])\n",
        "\n",
        "data_augmentation_hor = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# define prepare function from tensorflow website\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Use data augmentation only on the training set\n",
        "  if augment:\n",
        "    import random\n",
        "    rand = random.uniform(0, 1)\n",
        "    if rand == 0:\n",
        "      ds = ds.map(lambda x, y: (data_augmentation_hor(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "    else:\n",
        "      ds = ds.map(lambda x, y: (data_augmentation_ver(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "    \n",
        "  # Batch all datasets\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Use buffered prefecting on all datasets\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds = prepare(train_ds, shuffle=True, augment=False)\n",
        "val_ds = prepare(val_ds, shuffle=True)\n",
        "test_ds = prepare(test_ds, shuffle=True)\n",
        "\n",
        "print(tf.data.experimental.cardinality(train_ds))\n",
        "print(tf.data.experimental.cardinality(val_ds))\n",
        "print(tf.data.experimental.cardinality(test_ds))"
      ],
      "id": "MmZOkQDIYz2S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(200, shape=(), dtype=int64)\n",
            "tf.Tensor(50, shape=(), dtype=int64)\n",
            "tf.Tensor(63, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngEpTvpdksXg"
      },
      "source": [
        "# Model choosing"
      ],
      "id": "ngEpTvpdksXg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb8d216"
      },
      "source": [
        "**Build 3D CNN Model from scratch**\n",
        "\n",
        "adapted by: https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130"
      ],
      "id": "dfb8d216"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1f5fa6"
      },
      "source": [
        "base_model = Sequential() # sequential model\n",
        "base_model.add(Conv3D(32, kernel_size=(4, 4, 4), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(12, 33, 33, 6)))\n",
        "base_model.add(Conv3D(32, kernel_size=(4, 4, 4), activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
        "base_model.add(MaxPooling3D(pool_size=(4, 4, 4)))\n",
        "base_model.add(BatchNormalization(center=True, scale=True))\n",
        "base_model.add(Dropout(0.4))\n",
        "base_model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "base_model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "#base_model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
        "base_model.add(BatchNormalization(center=True, scale=True))\n",
        "base_model.add(Dropout(0.4))\n",
        "base_model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "base_model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
        "base_model.add(BatchNormalization(center=True, scale=True))\n",
        "#base_model.add(GlobalAveragePooling3D((4, 4, 4))\n",
        "base_model.add(Flatten())\n",
        "base_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dropout(0.4))\n",
        "base_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dropout(0.4))\n",
        "base_model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dropout(0.4))\n",
        "base_model.add(Dense(11, activation='softmax')) # number of outputs, in our case eleven different classes"
      ],
      "id": "3d1f5fa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a5975d9",
        "outputId": "3a26e933-8c53-44e7-f567-9bd5bfbc1948"
      },
      "source": [
        "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "base_model.summary()"
      ],
      "id": "3a5975d9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 12, 33, 33, 32)    5216      \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 31, 31, 32)    27680     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 10, 31, 31, 32)    128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10, 31, 31, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 10, 31, 31, 64)    55360     \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 8, 29, 29, 64)     110656    \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 4, 14, 14, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 14, 14, 64)     256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 14, 14, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 4, 14, 14, 128)    221312    \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 2, 12, 12, 128)    442496    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 1, 6, 6, 128)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1, 6, 6, 128)      512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 6, 6, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                1419      \n",
            "=================================================================\n",
            "Total params: 2,077,835\n",
            "Trainable params: 2,077,387\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_RdSzhJk4pS"
      },
      "source": [
        "# Model training"
      ],
      "id": "B_RdSzhJk4pS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmWvkOCk6viT"
      },
      "source": [
        "**Define callbacks**"
      ],
      "id": "cmWvkOCk6viT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3guZwu-6sMm"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "learningrate_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "early_stopping_cb = EarlyStopping(monitor='val_accuracy', patience = 15)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"own_model.h5\", save_best_only=True)"
      ],
      "id": "I3guZwu-6sMm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "763b2191"
      },
      "source": [
        "**Fitting Model**"
      ],
      "id": "763b2191"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c07424ad",
        "outputId": "2cddfdcd-96ef-45e5-9739-66690c3a5d7a"
      },
      "source": [
        "#%%script false\n",
        "# history = base_model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "#                     validation_data=(X_val, y_val), callbacks=[checkpoint_cb, early_stopping_cb],\n",
        "#                     class_weight=class_weights_dict)\n",
        "\n",
        "history = base_model.fit(train_ds, epochs=100, batch_size=32, \n",
        "                    validation_data=val_ds, callbacks=[checkpoint_cb, early_stopping_cb, learningrate_cb],\n",
        "                    class_weight=class_weights_dict)"
      ],
      "id": "c07424ad",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - 148s 500ms/step - loss: 3.2007 - accuracy: 0.1827 - val_loss: 2.5400 - val_accuracy: 0.1138\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 100s 498ms/step - loss: 2.1023 - accuracy: 0.1809 - val_loss: 1.7936 - val_accuracy: 0.2362\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 100s 498ms/step - loss: 1.7474 - accuracy: 0.2310 - val_loss: 1.6424 - val_accuracy: 0.3525\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 100s 498ms/step - loss: 1.6439 - accuracy: 0.2801 - val_loss: 1.4606 - val_accuracy: 0.4137\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 100s 498ms/step - loss: 1.4777 - accuracy: 0.3459 - val_loss: 1.6260 - val_accuracy: 0.3363\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 100s 498ms/step - loss: 1.4146 - accuracy: 0.3534 - val_loss: 1.5893 - val_accuracy: 0.3444\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 1.3855 - accuracy: 0.4113 - val_loss: 1.4991 - val_accuracy: 0.4300\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 1.3666 - accuracy: 0.4315 - val_loss: 1.3451 - val_accuracy: 0.4806\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 1.2904 - accuracy: 0.4763 - val_loss: 1.7612 - val_accuracy: 0.3506\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 1.2163 - accuracy: 0.4607 - val_loss: 1.1553 - val_accuracy: 0.5769\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 1.2690 - accuracy: 0.4528 - val_loss: 1.4782 - val_accuracy: 0.4487\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 1.2256 - accuracy: 0.4810 - val_loss: 1.0097 - val_accuracy: 0.6556\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 1.0924 - accuracy: 0.5144 - val_loss: 1.7591 - val_accuracy: 0.4212\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 1.1567 - accuracy: 0.4776 - val_loss: 1.1917 - val_accuracy: 0.5431\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 0.9904 - accuracy: 0.5575 - val_loss: 1.1444 - val_accuracy: 0.5831\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.9517 - accuracy: 0.5855 - val_loss: 1.0549 - val_accuracy: 0.6231\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.9141 - accuracy: 0.5841 - val_loss: 1.1376 - val_accuracy: 0.5562\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.8934 - accuracy: 0.5879 - val_loss: 1.2564 - val_accuracy: 0.5487\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.8130 - accuracy: 0.6139 - val_loss: 1.0132 - val_accuracy: 0.6256\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.7782 - accuracy: 0.6207 - val_loss: 1.3336 - val_accuracy: 0.5419\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.7555 - accuracy: 0.6449 - val_loss: 1.1011 - val_accuracy: 0.5894\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.7382 - accuracy: 0.6340 - val_loss: 0.9108 - val_accuracy: 0.6800\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.6866 - accuracy: 0.6534 - val_loss: 0.9876 - val_accuracy: 0.6425\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.6430 - accuracy: 0.6744 - val_loss: 0.9640 - val_accuracy: 0.6531\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 0.6153 - accuracy: 0.6838 - val_loss: 0.8352 - val_accuracy: 0.7175\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 100s 502ms/step - loss: 0.5785 - accuracy: 0.7083 - val_loss: 0.9601 - val_accuracy: 0.6681\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.5475 - accuracy: 0.7244 - val_loss: 0.9974 - val_accuracy: 0.6662\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 100s 502ms/step - loss: 0.5301 - accuracy: 0.7216 - val_loss: 0.8819 - val_accuracy: 0.7025\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.5038 - accuracy: 0.7281 - val_loss: 0.8796 - val_accuracy: 0.7025\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.4551 - accuracy: 0.7505 - val_loss: 0.8754 - val_accuracy: 0.7031\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 0.4261 - accuracy: 0.7613 - val_loss: 0.9553 - val_accuracy: 0.6769\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 100s 499ms/step - loss: 0.4095 - accuracy: 0.7684 - val_loss: 1.0232 - val_accuracy: 0.6469\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3875 - accuracy: 0.7696 - val_loss: 0.9338 - val_accuracy: 0.6812\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3909 - accuracy: 0.7754 - val_loss: 0.8637 - val_accuracy: 0.7075\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3626 - accuracy: 0.7787 - val_loss: 0.8819 - val_accuracy: 0.7006\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3357 - accuracy: 0.7861 - val_loss: 0.9503 - val_accuracy: 0.6825\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3255 - accuracy: 0.8045 - val_loss: 0.8792 - val_accuracy: 0.7163\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.3146 - accuracy: 0.8031 - val_loss: 0.9103 - val_accuracy: 0.7038\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2966 - accuracy: 0.8091 - val_loss: 0.9754 - val_accuracy: 0.6850\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2899 - accuracy: 0.8135 - val_loss: 0.8877 - val_accuracy: 0.7188\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2874 - accuracy: 0.8184 - val_loss: 0.8934 - val_accuracy: 0.7131\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2801 - accuracy: 0.8201 - val_loss: 0.9212 - val_accuracy: 0.7056\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2791 - accuracy: 0.8241 - val_loss: 0.9015 - val_accuracy: 0.7113\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2605 - accuracy: 0.8240 - val_loss: 0.9028 - val_accuracy: 0.7138\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2381 - accuracy: 0.8375 - val_loss: 0.8904 - val_accuracy: 0.7144\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2553 - accuracy: 0.8369 - val_loss: 0.8907 - val_accuracy: 0.7156\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 100s 502ms/step - loss: 0.2463 - accuracy: 0.8421 - val_loss: 0.9173 - val_accuracy: 0.7063\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2394 - accuracy: 0.8402 - val_loss: 0.9214 - val_accuracy: 0.7044\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2417 - accuracy: 0.8462 - val_loss: 0.8958 - val_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2301 - accuracy: 0.8510 - val_loss: 0.8968 - val_accuracy: 0.7169\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2427 - accuracy: 0.8452 - val_loss: 0.9311 - val_accuracy: 0.7038\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2146 - accuracy: 0.8488 - val_loss: 0.9141 - val_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2271 - accuracy: 0.8456 - val_loss: 0.8943 - val_accuracy: 0.7306\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2110 - accuracy: 0.8594 - val_loss: 0.9103 - val_accuracy: 0.7231\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2110 - accuracy: 0.8469 - val_loss: 0.9108 - val_accuracy: 0.7206\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2200 - accuracy: 0.8482 - val_loss: 0.9045 - val_accuracy: 0.7225\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2027 - accuracy: 0.8598 - val_loss: 0.8938 - val_accuracy: 0.7275\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2217 - accuracy: 0.8463 - val_loss: 0.9051 - val_accuracy: 0.7219\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2101 - accuracy: 0.8603 - val_loss: 0.9083 - val_accuracy: 0.7237\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2018 - accuracy: 0.8573 - val_loss: 0.9121 - val_accuracy: 0.7212\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2127 - accuracy: 0.8442 - val_loss: 0.9051 - val_accuracy: 0.7262\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2065 - accuracy: 0.8484 - val_loss: 0.9114 - val_accuracy: 0.7212\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 100s 500ms/step - loss: 0.2051 - accuracy: 0.8525 - val_loss: 0.9104 - val_accuracy: 0.7219\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 101s 503ms/step - loss: 0.2064 - accuracy: 0.8561 - val_loss: 0.9120 - val_accuracy: 0.7244\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2015 - accuracy: 0.8520 - val_loss: 0.9118 - val_accuracy: 0.7275\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 100s 501ms/step - loss: 0.2087 - accuracy: 0.8557 - val_loss: 0.9147 - val_accuracy: 0.7237\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 101s 502ms/step - loss: 0.2047 - accuracy: 0.8565 - val_loss: 0.9083 - val_accuracy: 0.7294\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 100s 502ms/step - loss: 0.2189 - accuracy: 0.8467 - val_loss: 0.9076 - val_accuracy: 0.7256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0990405d"
      },
      "source": [
        "%%script false\n",
        "base_model.save('gdrive/My Drive/Wirtschaftsinformatik/lulc_data/own_trainingData_210714.h5') # save model in root directory\n",
        "model = keras.models.load_model('own_model.h5')"
      ],
      "id": "0990405d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0ff6ad"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "ee0ff6ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d095da8"
      },
      "source": [
        "#%%script false\n",
        "# Calculate loss and accuracy\n",
        "base_model.evaluate(X_test, y_test)"
      ],
      "id": "2d095da8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "324f8b8a",
        "outputId": "c607d4a2-bac7-4a7b-a1d1-964c3a2c9620"
      },
      "source": [
        "#%%script false\n",
        "#Plot accuracy and loss of train and val set\n",
        "plt.figure(figsize=(11,4))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['accuracy'], color=\"green\")\n",
        "plt.plot(history.history['val_accuracy'], color=\"blue\")\n",
        "plt.title(\"Accuracy\", fontsize=16)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'], color=\"red\",)\n",
        "plt.plot(history.history['val_loss'], color=\"orange\")\n",
        "plt.title(\"Loss\", fontsize=16)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "id": "324f8b8a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40757eea16ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%script false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Plot accuracy and loss of train and val set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"green\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXavZC-WlC7l"
      },
      "source": [
        "# Make Predictions"
      ],
      "id": "OXavZC-WlC7l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e65cd20e"
      },
      "source": [
        "**Testing on Public Test Set**"
      ],
      "id": "e65cd20e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbf228c"
      },
      "source": [
        "data_public_test = np.load(root_path + '/public_test.npz') # load public test set\n",
        "bands_public_test = data_public_test['bands'] # extract only layer called 'bands'\n",
        "print(bands_public_test.shape)"
      ],
      "id": "adbf228c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50ad6025"
      },
      "source": [
        "# Show all 12 monthly images of the public test set\n",
        "\n",
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands_public_test[month, :, :, channel]\n",
        "        plt.imshow(image, cmap = plt.cm.binary)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\")"
      ],
      "id": "50ad6025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49736550"
      },
      "source": [
        "**Padding**\n",
        "\n",
        "To be able to use the sliding window approach on the public test set."
      ],
      "id": "49736550"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10a797da"
      },
      "source": [
        "bands_public_test_pad = np.zeros(shape=(12, 532, 532, 6)) # get empty array with correct shape\n",
        "\n",
        "# perform padding for all images (months and channels)\n",
        "for month in range(12):\n",
        "    for channel in range(6):\n",
        "        bands_public_test_pad[month, :, :,channel] = np.pad(bands_public_test[month, :, :,channel],\n",
        "                                                            ((16,16),(16,16)), 'constant')\n",
        "        \n",
        "print(bands_public_test_pad.shape)"
      ],
      "id": "10a797da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "753a19b2"
      },
      "source": [
        "Test padding by printing out the images of the public test set."
      ],
      "id": "753a19b2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24410240"
      },
      "source": [
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands_public_test_pad[month, :, :, channel]\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\") "
      ],
      "id": "24410240",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46ce5396"
      },
      "source": [
        "# add one dimension to be able feeding our model\n",
        "\n",
        "#bands_public_test = np.expand_dims(bands_public_test, 0)\n",
        "bands_public_test_pad = np.expand_dims(bands_public_test_pad, 0)\n",
        "bands_public_test_pad.shape"
      ],
      "id": "46ce5396",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5a2de1"
      },
      "source": [
        "**Naive sliding window approach**\n",
        "\n",
        "Iterate the model over the whole public test image with stepsize one."
      ],
      "id": "dd5a2de1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82089500",
        "scrolled": true
      },
      "source": [
        "x_coord_start = 15\n",
        "x_coord_end = x_coord_start + 33\n",
        "\n",
        "#print(current_cutout.shape) #(1, 12, 33, 33, 6)\n",
        "y_pred_public_test = np.zeros(shape=(500, 500, 1))\n",
        "\n",
        "for i in range(468):\n",
        "    x_coord_end   += 1\n",
        "    x_coord_start += 1\n",
        "    y_coord_start = 15\n",
        "    y_coord_end = y_coord_start + 33\n",
        "    for j in range(468):\n",
        "        y_coord_end   += 1\n",
        "        y_coord_start += 1\n",
        "        # pass every month & color channel \n",
        "        current_cutout = bands_public_test_pad[:, :, x_coord_start:x_coord_end, y_coord_start:y_coord_end, :]\n",
        "        \n",
        "        y_pred = base_model.predict_classes(current_cutout)\n",
        "        y_pred_public_test[i][j] = y_pred[0]\n",
        "        \n",
        "        #Debugging\n",
        "        #print(\"i: \"+ str(i) + \"  j: \" + str(j)        + \"  -  \" +\n",
        "        #      str(x_coord_start)+\":\"+str(x_coord_end) + \"; \"    +\n",
        "        #      str(y_coord_start)+\":\"+str(y_coord_end) + \"  -  \" +\n",
        "        #      str(int(y_pred_public_test[i][j])))\n",
        "        #if(current_cutout.shape != (1, 12, 33, 33, 6)): \n",
        "            #print(str(current_cutout.shape) + \"\\n\")"
      ],
      "id": "82089500",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d85a1a1f"
      },
      "source": [
        "#%%script false\n",
        "with open(\"gdrive/My Drive/Wirtschaftsinformatik/lulc_data/y_pred_public_test.npy\", \"wb\") as f:\n",
        "    np.save(f, y_pred_public_test)"
      ],
      "id": "d85a1a1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d901abe8"
      },
      "source": [
        "#%%script false\n",
        "with open(\"gdrive/My Drive/Wirtschaftsinformatik/lulc_data/y_pred_public_test.npy\", \"rb\") as f:\n",
        "    y_pred_public_test = np.load(f)"
      ],
      "id": "d901abe8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93e295a1"
      },
      "source": [
        "**Visualization of the result for the public test set**\n",
        "\n",
        "Code adapted from https://stackoverflow.com/questions/37719304/python-imshow-set-certain-value-to-defined-color"
      ],
      "id": "93e295a1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696331a3"
      },
      "source": [
        "color_map = {\n",
        "    0:  np.array([  0,   0,   0]), #0: \"No Data\"\n",
        "    1:  np.array([240, 222,  60]), #1: \"Cultivated Land\"\n",
        "    2:  np.array([ 47, 102,  31]), #2: \"Forest\"\n",
        "    3:  np.array([162, 232, 142]), #3: \"Grassland\"\n",
        "    4:  np.array([162, 176, 158]), #4: \"Shrubland\"\n",
        "    5:  np.array([ 99, 189, 224]), #5: \"Water\"\n",
        "    6:  np.array([ 44, 209, 154]), #6: \"Wetlands\"\n",
        "    7:  np.array([230, 189,  41]), #7: \"Tundra\"\n",
        "    8:  np.array([237,  82,  55]), #8: \"Artificial Surface\"\n",
        "    9:  np.array([224, 180, 132]), #9: \"Bareland\"\n",
        "    10: np.array([189, 189, 189]), #10: \"Snow and Ice\"\n",
        "} \n",
        "\n",
        "# make a 3d numpy array that has a color channel dimension   \n",
        "data_3d = np.ndarray(shape=(y_pred_public_test.shape[0], y_pred_public_test.shape[1],3), dtype=int)\n",
        "for i in range(0, y_pred_public_test.shape[0]):\n",
        "    for j in range(0, y_pred_public_test.shape[1]):\n",
        "        data_3d[i][j] = color_map[y_pred_public_test[j,i,0]]\n",
        "        print(data_3d[i][j])\n",
        "\n",
        "# display the plot \n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.imshow(data_3d)"
      ],
      "id": "696331a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB6peSfUzctg"
      },
      "source": [
        "# display the plot \n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.imshow(data_3d)"
      ],
      "id": "rB6peSfUzctg",
      "execution_count": null,
      "outputs": []
    }
  ]
}