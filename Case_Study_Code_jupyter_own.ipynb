{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Case_Study_Code_jupyter_own.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OXavZC-WlC7l"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5c3db8a"
      },
      "source": [
        "**VM: Deep Learning mit Python - Model from scratch**\n",
        "\n",
        "*Group: Leo Giesen, Johannes Kauffmann*\n",
        "\n",
        "Case Study: Create deep learning model to predict Land Use and Land Cover data drom satellite pictures."
      ],
      "id": "c5c3db8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6fIXK3Kg0xb"
      },
      "source": [
        "# Imports and definitions"
      ],
      "id": "t6fIXK3Kg0xb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e03219a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402523d0-4415-4c00-cfc0-dd18272ef86a"
      },
      "source": [
        "# Import of packages\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import calendar\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import tensorflow_hub as hub\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive"
      ],
      "id": "5e03219a",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opEjKvyLk4s2"
      },
      "source": [
        "# mount Google drive to get the data\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Wirtschaftsinformatik/lulc_data'"
      ],
      "id": "opEjKvyLk4s2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90bd882"
      },
      "source": [
        "# Class names\n",
        "\n",
        "class_names = {\n",
        "    0: \"No Data\", \n",
        "    1: \"Cultivated Land\",\n",
        "    2: \"Forest\",\n",
        "    3: \"Grassland\",\n",
        "    4: \"Shrubland\",\n",
        "    5: \"Water\",\n",
        "    6: \"Wetlands\",\n",
        "    7: \"Tundra\",\n",
        "    8: \"Artificial Surface\",\n",
        "    9: \"Bareland\",\n",
        "    10: \"Snow and Ice\"\n",
        "}"
      ],
      "id": "f90bd882",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89bafeee"
      },
      "source": [
        "# Channel names\n",
        "\n",
        "channel_names = {\n",
        "    1: \"Red\",\n",
        "    2: \"Green\",\n",
        "    3: \"Blue\",\n",
        "    4: \"NIR 1\",\n",
        "    5: \"NIR 2\",\n",
        "    6: \"NIR 3\"\n",
        "}"
      ],
      "id": "89bafeee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTqe8geCke8B"
      },
      "source": [
        "# Data loading and exploration"
      ],
      "id": "OTqe8geCke8B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "622facde"
      },
      "source": [
        "**Loading data**"
      ],
      "id": "622facde"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64f8087f"
      },
      "source": [
        "data = data = np.load(root_path + '/train.npz')\n",
        "bands = data['bands'] # data: 10.000 patches, each for twelve months and with six channels. Resolution: 33x33 pixels\n",
        "lulc = data['lulc'] # labels for central pixel of patches (Land Use and Land Cover)\n",
        "print(bands.shape)\n",
        "print(lulc.shape)"
      ],
      "id": "64f8087f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqHYEAe2lzUe"
      },
      "source": [
        "**Examine data**"
      ],
      "id": "zqHYEAe2lzUe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98968898"
      },
      "source": [
        "#%%script false\n",
        "# show number of instances per class\n",
        "\n",
        "count_classes = []\n",
        "for i in range(11): \n",
        "    val = np.count_nonzero(lulc == i)\n",
        "    print(\"class \"+str(i)+\": \"+str(val))\n",
        "    count_classes.append(val)\n",
        "#print(count_classes)"
      ],
      "id": "98968898",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEpdHvAy8cc"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "langs = [0,1,2,3,4,5,6,7,8,9,10]\n",
        "students = count_classes\n",
        "ax.bar(langs,students)\n",
        "plt.show()"
      ],
      "id": "qIEpdHvAy8cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3abcb8"
      },
      "source": [
        "--> Realization: Class 2 is over-represented. Classes 6, 7 and 10 are not present in the data set at all."
      ],
      "id": "6e3abcb8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da34908c",
        "scrolled": true
      },
      "source": [
        "%%script false\n",
        "# Show some images\n",
        "\n",
        "patch = 250 # patch number\n",
        "\n",
        "print(\"Channels from patch no. \" + str(patch))\n",
        "print(\"Central pixel is labeled as \" + class_names[lulc[patch]])\n",
        "\n",
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands[patch, month, :, :, channel]\n",
        "        plt.imshow(image, cmap = plt.cm.binary)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\")"
      ],
      "id": "da34908c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648cCzbdg_bm"
      },
      "source": [
        "# Data Preparation"
      ],
      "id": "648cCzbdg_bm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2819dc3d"
      },
      "source": [
        "**Split data into train, validation and test data**"
      ],
      "id": "2819dc3d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaed0901"
      },
      "source": [
        "X = bands\n",
        "y = lulc\n",
        "\n",
        "# split into train, test, vaildation sets\n",
        "X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.20)\n",
        "print(X_train.shape)"
      ],
      "id": "aaed0901",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOFxAzX6oKs"
      },
      "source": [
        "# clear variables to save RAM\n",
        "del data\n",
        "del bands\n",
        "del lulc\n",
        "del X\n",
        "del y"
      ],
      "id": "nmOFxAzX6oKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a914c2c"
      },
      "source": [
        "**Class weights** "
      ],
      "id": "9a914c2c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90976991"
      },
      "source": [
        "# Calculate class weights automatically\n",
        "class_weights_array = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "# Create dictionary for the class weights\n",
        "class_weights_dict = {\n",
        "    0: class_weights_array[0],\n",
        "    1: class_weights_array[1],\n",
        "    2: class_weights_array[2],\n",
        "    3: class_weights_array[3],\n",
        "    4: class_weights_array[4],\n",
        "    5: class_weights_array[5],\n",
        "    6: 0,\n",
        "    7: 0,\n",
        "    8: class_weights_array[6],\n",
        "    9: class_weights_array[7],\n",
        "    10: 0,\n",
        "}\n",
        "\n",
        "print(class_weights_dict)"
      ],
      "id": "90976991",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ3_3mFhTWrE"
      },
      "source": [
        "**One-hot encoder**"
      ],
      "id": "WJ3_3mFhTWrE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "endRIo0fTSDj"
      },
      "source": [
        "# one-hot encoder for categorical_crossentropy loss to work in model\n",
        "depth = 11\n",
        "y_train = tf.one_hot(y_train, depth)\n",
        "y_val = tf.one_hot(y_val, depth)\n",
        "y_test = tf.one_hot(y_test, depth)"
      ],
      "id": "endRIo0fTSDj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEOzTGMcgoHq"
      },
      "source": [
        "**Data augmentation**"
      ],
      "id": "NEOzTGMcgoHq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8s2bWDmq2o1"
      },
      "source": [
        "#%%script false\n",
        "# Create Tensorflow Dataset objects\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "print(tf.data.experimental.cardinality(train_ds))\n",
        "print(tf.data.experimental.cardinality(val_ds))\n",
        "print(tf.data.experimental.cardinality(test_ds))"
      ],
      "id": "Y8s2bWDmq2o1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaqO68xP7Qpu"
      },
      "source": [
        "# clear variables to save RAM\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val"
      ],
      "id": "AaqO68xP7Qpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZOkQDIYz2S"
      },
      "source": [
        "#%%script false\n",
        "# create data augmentation layer\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# define prepare function from tensorflow website\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Use data augmentation only on the training set\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "    \n",
        "  # Batch all datasets\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Use buffered prefecting on all datasets\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
        "#train_ds = train_ds.concatenate(train_ds_aug)\n",
        "val_ds = prepare(val_ds, shuffle=True)\n",
        "test_ds = prepare(test_ds, shuffle=True)\n",
        "\n",
        "print(tf.data.experimental.cardinality(train_ds))\n",
        "print(tf.data.experimental.cardinality(val_ds))\n",
        "print(tf.data.experimental.cardinality(test_ds))"
      ],
      "id": "MmZOkQDIYz2S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngEpTvpdksXg"
      },
      "source": [
        "# Model choosing"
      ],
      "id": "ngEpTvpdksXg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb8d216"
      },
      "source": [
        "**Build 3D CNN Model from scratch**\n",
        "\n",
        "adapted by: https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130"
      ],
      "id": "dfb8d216"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1f5fa6"
      },
      "source": [
        "base_model = Sequential() # sequential model\n",
        "base_model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(12, 33,33,6)))\n",
        "base_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "base_model.add(BatchNormalization(center=True, scale=True))\n",
        "#base_model.add(Dropout(0.5))\n",
        "base_model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "base_model.add(BatchNormalization(center=True, scale=True))\n",
        "#base_model.add(Dropout(0.5))\n",
        "base_model.add(Flatten())\n",
        "base_model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
        "base_model.add(Dense(11, activation='softmax')) # number of outputs, in our case eleven different classes"
      ],
      "id": "3d1f5fa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a5975d9"
      },
      "source": [
        "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "base_model.summary()"
      ],
      "id": "3a5975d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_RdSzhJk4pS"
      },
      "source": [
        "# Model training"
      ],
      "id": "B_RdSzhJk4pS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "763b2191"
      },
      "source": [
        "**Fitting Models**"
      ],
      "id": "763b2191"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c07424ad"
      },
      "source": [
        "#%%script false\n",
        "# define callbacks\n",
        "early_stopping_cb = EarlyStopping(monitor='val_accuracy', patience = 15)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"own_model.h5\", save_best_only=True)\n",
        "\n",
        "# fit the model\n",
        "\n",
        "# history = base_model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "#                     validation_data=(X_val, y_val), callbacks=[checkpoint_cb, early_stopping_cb],\n",
        "#                     class_weight=class_weights_dict)\n",
        "\n",
        "history = base_model.fit(train_ds, epochs=100, batch_size=32, \n",
        "                    validation_data=val_ds, callbacks=[checkpoint_cb, early_stopping_cb],\n",
        "                    class_weight=class_weights_dict)"
      ],
      "id": "c07424ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0990405d"
      },
      "source": [
        "#%%script false\n",
        "#base_model.save('gdrive/My Drive/Wirtschaftsinformatik/lulc_data/own_trainingData_500Epochs.h5') # save model in root directory\n",
        "model = keras.models.load_model('own_model.h5')"
      ],
      "id": "0990405d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0ff6ad"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "ee0ff6ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d095da8"
      },
      "source": [
        "#%%script false\n",
        "# Calculate loss and accuracy\n",
        "base_model.evaluate(X_test, y_test)"
      ],
      "id": "2d095da8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324f8b8a"
      },
      "source": [
        "#%%script false\n",
        "#Plot accuracy and loss of train and val set\n",
        "plt.figure(figsize=(11,4))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['accuracy'], color=\"green\")\n",
        "plt.plot(history.history['val_accuracy'], color=\"blue\")\n",
        "plt.title(\"Accuracy\", fontsize=16)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'], color=\"red\",)\n",
        "plt.plot(history.history['val_loss'], color=\"orange\")\n",
        "plt.title(\"Loss\", fontsize=16)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "id": "324f8b8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXavZC-WlC7l"
      },
      "source": [
        "# Make Predictions"
      ],
      "id": "OXavZC-WlC7l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e65cd20e"
      },
      "source": [
        "**Testing on Public Test Set**"
      ],
      "id": "e65cd20e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbf228c"
      },
      "source": [
        "data_public_test = np.load(root_path + '/public_test.npz') # load public test set\n",
        "bands_public_test = data_public_test['bands'] # extract only layer called 'bands'\n",
        "print(bands_public_test.shape)"
      ],
      "id": "adbf228c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50ad6025"
      },
      "source": [
        "# Show all 12 monthly images of the public test set\n",
        "\n",
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands_public_test[month, :, :, channel]\n",
        "        plt.imshow(image, cmap = plt.cm.binary)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\")"
      ],
      "id": "50ad6025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49736550"
      },
      "source": [
        "**Padding**\n",
        "\n",
        "To be able to use the sliding window approach on the public test set."
      ],
      "id": "49736550"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10a797da"
      },
      "source": [
        "bands_public_test_pad = np.zeros(shape=(12, 532, 532, 6)) # get empty array with correct shape\n",
        "\n",
        "# perform padding for all images (months and channels)\n",
        "for month in range(12):\n",
        "    for channel in range(6):\n",
        "        bands_public_test_pad[month, :, :,channel] = np.pad(bands_public_test[month, :, :,channel],\n",
        "                                                            ((16,16),(16,16)), 'constant')\n",
        "        \n",
        "print(bands_public_test_pad.shape)"
      ],
      "id": "10a797da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "753a19b2"
      },
      "source": [
        "Test padding by printing out the images of the public test set."
      ],
      "id": "753a19b2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24410240"
      },
      "source": [
        "for month in range(12):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for channel in range(6): #show all six channels\n",
        "        ax = plt.subplot(3, 3, channel+1)\n",
        "        image = bands_public_test_pad[month, :, :, channel]\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
        "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
        "        plt.axis(\"off\") "
      ],
      "id": "24410240",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46ce5396"
      },
      "source": [
        "# add one dimension to be able feeding our model\n",
        "\n",
        "#bands_public_test = np.expand_dims(bands_public_test, 0)\n",
        "bands_public_test_pad = np.expand_dims(bands_public_test_pad, 0)\n",
        "bands_public_test_pad.shape"
      ],
      "id": "46ce5396",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5a2de1"
      },
      "source": [
        "**Naive sliding window approach**\n",
        "\n",
        "Iterate the model over the whole public test image with stepsize one."
      ],
      "id": "dd5a2de1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82089500",
        "scrolled": true
      },
      "source": [
        "x_coord_start = 15\n",
        "x_coord_end = x_coord_start + 33\n",
        "\n",
        "#print(current_cutout.shape) #(1, 12, 33, 33, 6)\n",
        "y_pred_public_test = np.zeros(shape=(500, 500, 1))\n",
        "\n",
        "for i in range(468):\n",
        "    x_coord_end   += 1\n",
        "    x_coord_start += 1\n",
        "    y_coord_start = 15\n",
        "    y_coord_end = y_coord_start + 33\n",
        "    for j in range(468):\n",
        "        y_coord_end   += 1\n",
        "        y_coord_start += 1\n",
        "        # pass every month & color channel \n",
        "        current_cutout = bands_public_test_pad[:, :, x_coord_start:x_coord_end, y_coord_start:y_coord_end, :]\n",
        "        \n",
        "        y_pred = base_model.predict_classes(current_cutout)\n",
        "        y_pred_public_test[i][j] = y_pred[0]\n",
        "        \n",
        "        #Debugging\n",
        "        #print(\"i: \"+ str(i) + \"  j: \" + str(j)        + \"  -  \" +\n",
        "        #      str(x_coord_start)+\":\"+str(x_coord_end) + \"; \"    +\n",
        "        #      str(y_coord_start)+\":\"+str(y_coord_end) + \"  -  \" +\n",
        "        #      str(int(y_pred_public_test[i][j])))\n",
        "        #if(current_cutout.shape != (1, 12, 33, 33, 6)): \n",
        "            #print(str(current_cutout.shape) + \"\\n\")"
      ],
      "id": "82089500",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d85a1a1f"
      },
      "source": [
        "#%%script false\n",
        "with open(\"gdrive/My Drive/Wirtschaftsinformatik/lulc_data/y_pred_public_test.npy\", \"wb\") as f:\n",
        "    np.save(f, y_pred_public_test)"
      ],
      "id": "d85a1a1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d901abe8"
      },
      "source": [
        "#%%script false\n",
        "with open(\"gdrive/My Drive/Wirtschaftsinformatik/lulc_data/y_pred_public_test.npy\", \"rb\") as f:\n",
        "    y_pred_public_test = np.load(f)"
      ],
      "id": "d901abe8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93e295a1"
      },
      "source": [
        "**Visualization of the result for the public test set**\n",
        "\n",
        "Code adapted from https://stackoverflow.com/questions/37719304/python-imshow-set-certain-value-to-defined-color"
      ],
      "id": "93e295a1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696331a3"
      },
      "source": [
        "color_map = {\n",
        "    0:  np.array([  0,   0,   0]), #0: \"No Data\"\n",
        "    1:  np.array([240, 222,  60]), #1: \"Cultivated Land\"\n",
        "    2:  np.array([ 47, 102,  31]), #2: \"Forest\"\n",
        "    3:  np.array([162, 232, 142]), #3: \"Grassland\"\n",
        "    4:  np.array([162, 176, 158]), #4: \"Shrubland\"\n",
        "    5:  np.array([ 99, 189, 224]), #5: \"Water\"\n",
        "    6:  np.array([ 44, 209, 154]), #6: \"Wetlands\"\n",
        "    7:  np.array([230, 189,  41]), #7: \"Tundra\"\n",
        "    8:  np.array([237,  82,  55]), #8: \"Artificial Surface\"\n",
        "    9:  np.array([224, 180, 132]), #9: \"Bareland\"\n",
        "    10: np.array([189, 189, 189]), #10: \"Snow and Ice\"\n",
        "} \n",
        "\n",
        "# make a 3d numpy array that has a color channel dimension   \n",
        "data_3d = np.ndarray(shape=(y_pred_public_test.shape[0], y_pred_public_test.shape[1],3), dtype=int)\n",
        "for i in range(0, y_pred_public_test.shape[0]):\n",
        "    for j in range(0, y_pred_public_test.shape[1]):\n",
        "        data_3d[i][j] = color_map[y_pred_public_test[j,i,0]]\n",
        "        print(data_3d[i][j])\n",
        "\n",
        "# display the plot \n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.imshow(data_3d)"
      ],
      "id": "696331a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB6peSfUzctg"
      },
      "source": [
        "# display the plot \n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.imshow(data_3d)"
      ],
      "id": "rB6peSfUzctg",
      "execution_count": null,
      "outputs": []
    }
  ]
}