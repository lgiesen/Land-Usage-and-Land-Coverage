{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c3db8a",
   "metadata": {},
   "source": [
    "# VM: Deep Learning mit Python\n",
    "\n",
    "*Group: Leo Giesen, Johannes Kauffmann*\n",
    "\n",
    "Case Study: Create deep learning model to predict Land Use and Land Cover data drom satellite pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calendar\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416235b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_public_test = np.load('../data/public_test.npz')\n",
    "bands_public_test = data_public_test['bands']\n",
    "bands_public_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc85332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some images og the public test set\n",
    "\n",
    "for month in range(12):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for channel in range(6): #show all six channels\n",
    "        ax = plt.subplot(3, 3, channel+1)\n",
    "        image = bands_public_test[month, :, :, channel]\n",
    "        plt.imshow(image, cmap = plt.cm.binary)\n",
    "        plt.title(\"Channel: \" + channel_names[channel+1])\n",
    "        plt.suptitle(calendar.month_name[month+1], size=16)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one dimension to be able feeding our model\n",
    "bands_public_test = np.expand_dims(bands_public_test , 0)\n",
    "bands_public_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3e707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other group's approach\n",
    "import sys\n",
    "sys.path. append ('..')\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "#from src.d01_data import load_data\n",
    "#from src.d02_processing import sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.util import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba212d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = bands_public_test # other group: load_data.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape #(12, 500, 500, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_as_windows(image, (12, 33, 33, 6), step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape #(1, 468, 468, 1, 12, 33, 33, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_squeeze = p.squeeze(axis=0)\n",
    "patches_reshape = np.reshape(patches_squeeze, (219024,12, 33,33, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_reshape.shape #(219024, 12, 33, 33, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = sliding_window.extract_patches(image, 16, 33, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted _categorical_crossentropy (weights)\n",
    "        model.compile(loss=loss, optimizer='adam')\n",
    "    \"\"\"\n",
    "\n",
    "    weights = K.variable(weights)\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        Y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        Y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2492d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[1, 1, 0.2; 1,1,1,1,1,1,1,1]\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'model', 'simple_model 1')\n",
    "model = keras.models.load_model(path, custom_objects={ 'loss': weighted_categorical_crossentropy(weights) }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = patches.batch(1)\n",
    "pred = model.predict(patches_reshape)\n",
    "patches #‹BatchDataset shapes: (None, 12, 33, 33, 6) types: tf.float32>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = pred.argmax(axis=-1)\n",
    "pred_class_q = pp.reshape(pred class, (468,468))\n",
    "pred_class.shape #(219024,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcdfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.dirname(os.getcwd()), 'data', 'prediction_1')\n",
    "np.save(path, pred_class_q)\n",
    "plt.imshow(pred_class_q, cmap='hsv')\n",
    "plt.colorbar() #‹matplotlib.colorbar.Colorbar at 0x7fe5f0b68e10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315caef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
